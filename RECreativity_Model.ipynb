{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data basic description:\n",
      "          novelty   creativity      clarity   usefulness\n",
      "count  2884.00000  2884.000000  2883.000000  2883.000000\n",
      "mean      0.31068     3.789875     4.186264     3.902879\n",
      "std       0.95068     0.957049     0.805295     0.843559\n",
      "min      -1.00000     1.000000     1.000000     1.000000\n",
      "25%      -1.00000     3.000000     4.000000     3.000000\n",
      "50%       1.00000     4.000000     4.000000     4.000000\n",
      "75%       1.00000     4.000000     5.000000     4.000000\n",
      "max       1.00000     5.000000     5.000000     5.000000\n",
      "Data column\n",
      "Index(['novelty', 'requirement', 'creativity', 'clarity', 'usefulness',\n",
      "       'domain'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "df = pd.read_csv('C:/Users/Anupama/Documents/4thsem/THESIS/requirementEDA.csv',sep=',')\n",
    "print(\"Data basic description:\")\n",
    "print(df.describe())\n",
    "print(\"Data column\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of novel requirements 994\n",
      "Number of non-novel requirements 1890\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of novel requirements\", len(df[df.novelty==-1]))\n",
    "print(\"Number of non-novel requirements\", len(df[df.novelty==1]))\n",
    "df_requirement = df[\"requirement\"]\n",
    "df_novelty = df[\"novelty\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training data: 2307\n",
      "Length of test data: 577\n",
      "Length of regular requirements in training dataset 1509\n",
      "Length of Novel requirements in training dataset 798\n",
      "Length of regular requirements in testing dataset 381\n",
      "Length of Novel requirements in testing dataset 196\n"
     ]
    }
   ],
   "source": [
    "#### Splitting data to training and testing dataset\n",
    "requirement_train, requirement_test, novelty_train, novelty_test = train_test_split(df_requirement,df_novelty,test_size=0.2,random_state=4)\n",
    "print(\"Length of training data:\",len(requirement_train))\n",
    "print(\"Length of test data:\",len(requirement_test))\n",
    "print(\"Length of regular requirements in training dataset\",len(requirement_train[df.novelty==1]))\n",
    "print(\"Length of Novel requirements in training dataset\",len(requirement_train[df.novelty==-1]))\n",
    "print(\"Length of regular requirements in testing dataset\",len(requirement_test[df.novelty==1]))\n",
    "print(\"Length of Novel requirements in testing dataset\",len(requirement_test[df.novelty==-1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "regularTrainSet = requirement_train[df.novelty==1]\n",
    "novelTrainSet = requirement_train[df.novelty==-1]\n",
    "requirementTrain = cv.fit_transform(requirement_train.values.astype('U'))\n",
    "requirementTest = cv.fit_transform(requirement_test.values.astype('U'))\n",
    "regularTrainSet_converted = cv.transform(regularTrainSet.values.astype('U'))\n",
    "NovelTrainSet_converted = cv.transform(novelTrainSet.values.astype('U')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for Isolation Forest:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.27      0.09      0.14       196\n",
      "          1       0.65      0.87      0.75       381\n",
      "\n",
      "avg / total       0.52      0.61      0.54       577\n",
      "\n"
     ]
    }
   ],
   "source": [
    "############ Isolation Forest\n",
    "\n",
    "clf = IsolationForest(max_samples=150)\n",
    "clf.fit(regularTrainSet_converted)\n",
    "predictedResults = clf.predict(requirementTest)\n",
    "actualResults = np.array(novelty_test)\n",
    "\n",
    "result_IsolationForest = classification_report(actualResults,predictedResults)\n",
    "print(\"Classification report for Isolation Forest:\")\n",
    "print(result_IsolationForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical distribution of the dataset\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-66910a22dc3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdf_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minclude\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'float64'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'int64'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Numerical distribution of the dataset'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdf_num\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxlabelsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mylabelsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m \u001b[1;31m# ; avoid having the matplotlib verbose informations\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "df_num = df.select_dtypes(include = ['float64', 'int64'])\n",
    "print('Numerical distribution of the dataset')\n",
    "plt.figure(figsize=(9, 8))\n",
    "df_num.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8); # ; avoid having the matplotlib verbose informations\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
